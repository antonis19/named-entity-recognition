{
 "cells": [
  {
   "source": [
    "# Named Entity Recognition using CRF model\n",
    "In Natural Language Processing (NLP) an Entity Recognition is one of the common problem. The entity is referred to as the part of the text that is interested in. In NLP, NER is a method of extracting the relevant information from a large corpus and classifying those entities into predefined categories such as location, organization, name and so on. \n",
    "Information about lables: \n",
    "* geo = Geographical Entity\n",
    "* org = Organization\n",
    "* per = Person\n",
    "* gpe = Geopolitical Entity\n",
    "* tim = Time indicator\n",
    "* art = Artifact\n",
    "* eve = Event\n",
    "* nat = Natural Phenomenon\n",
    "\n",
    "        1. Total Words Count = 1354149 \n",
    "        2. Target Data Column: Tag"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn_crfsuite in /Users/wc72da/opt/anaconda3/lib/python3.7/site-packages (0.3.6)\r\n",
      "Requirement already satisfied: tqdm>=2.0 in /Users/wc72da/opt/anaconda3/lib/python3.7/site-packages (from sklearn_crfsuite) (4.42.1)\r\n",
      "Requirement already satisfied: tabulate in /Users/wc72da/opt/anaconda3/lib/python3.7/site-packages (from sklearn_crfsuite) (0.8.7)\r\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /Users/wc72da/opt/anaconda3/lib/python3.7/site-packages (from sklearn_crfsuite) (0.9.7)\r\n",
      "Requirement already satisfied: six in /Users/wc72da/opt/anaconda3/lib/python3.7/site-packages (from sklearn_crfsuite) (1.12.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv file\n",
    "df = pd.read_csv('./data/ner_dataset.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1          NaN             of   IN      O\n",
       "2          NaN  demonstrators  NNS      O\n",
       "3          NaN           have  VBP      O\n",
       "4          NaN        marched  VBN      O\n",
       "5          NaN        through   IN      O\n",
       "6          NaN         London  NNP  B-geo\n",
       "7          NaN             to   TO      O\n",
       "8          NaN        protest   VB      O\n",
       "9          NaN            the   DT      O"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display first 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47959</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>47959</td>\n",
       "      <td>35178</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sentence: 12812</td>\n",
       "      <td>the</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>52573</td>\n",
       "      <td>145807</td>\n",
       "      <td>887908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sentence #     Word      POS      Tag\n",
       "count             47959  1048575  1048575  1048575\n",
       "unique            47959    35178       42       17\n",
       "top     Sentence: 12812      the       NN        O\n",
       "freq                  1    52573   145807   887908"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations : \n",
    "* There are total 47959 sentences in the dataset.\n",
    "* Number unique words in the dataset are 35178.\n",
    "* Total 17 lables (Tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
       "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
       "       'I-eve', 'I-nat'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the unique Tags\n",
    "df['Tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    1000616\n",
       "Word                0\n",
       "POS                 0\n",
       "Tag                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking null values, if any.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of missing values in 'Sentence #' attribute. So we will use pandas fillna technique and use 'ffill' method which propagates last valid observation forward to next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1  Sentence: 1             of   IN      O\n",
       "2  Sentence: 1  demonstrators  NNS      O\n",
       "3  Sentence: 1           have  VBP      O\n",
       "4  Sentence: 1        marched  VBN      O\n",
       "5  Sentence: 1        through   IN      O\n",
       "6  Sentence: 1         London  NNP  B-geo\n",
       "7  Sentence: 1             to   TO      O\n",
       "8  Sentence: 1        protest   VB      O\n",
       "9  Sentence: 1            the   DT      O"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class te get sentence. The each sentence will be list of tuples with its tag and pos.\n",
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                       s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47959"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "#sentence with its pos and tag.\n",
    "sent = getter.get_text()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all the sentences in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47959"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Preparation\n",
    "These are the default features used by the NER in nltk. We can also modify it for our customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0] # the current word\n",
    "    postag = sent[i][1] # the POS tag of the current word\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(), # the current word (lowercase)\n",
    "        'word[-3:]': word[-3:],  # 3-character suffix\n",
    "        'word[-2:]': word[-2:],  # 3-character suffix\n",
    "        'word.isupper()': word.isupper(), # is the word uppercase?\n",
    "        'word.istitle()': word.istitle(), # is the word lowercase?\n",
    "        'word.isdigit()': word.isdigit(), # it the word a number?\n",
    "        'postag': postag, # the POS tag of the word\n",
    "        'postag[:2]': postag[:2], # last 2 character of the POS tag of the word\n",
    "    }\n",
    "    if i > 0: # if not first word add features for previous word \n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else: # if first word of sentence there is no previous word\n",
    "        features['BOS'] = True # beginning of sentence\n",
    "\n",
    "    if i < len(sent)-1: # if not last word add features for next word\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True # end of sentence\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 38367/38367 [00:11<00:00, 3311.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 137852\n",
      "Seconds required: 3.021\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=2.49  loss=1350046.65 active=136849 feature_norm=1.00\n",
      "Iter 2   time=2.50  loss=1058045.46 active=135456 feature_norm=4.40\n",
      "Iter 3   time=1.26  loss=826851.07 active=129772 feature_norm=3.85\n",
      "Iter 4   time=6.26  loss=453638.15 active=131222 feature_norm=3.25\n",
      "Iter 5   time=1.27  loss=380487.14 active=133100 feature_norm=4.08\n",
      "Iter 6   time=1.26  loss=295215.85 active=131703 feature_norm=5.87\n",
      "Iter 7   time=1.27  loss=256492.12 active=124507 feature_norm=7.20\n",
      "Iter 8   time=1.24  loss=228096.14 active=118624 feature_norm=8.21\n",
      "Iter 9   time=1.30  loss=197310.30 active=110543 feature_norm=10.41\n",
      "Iter 10  time=1.42  loss=179154.00 active=107538 feature_norm=11.66\n",
      "Iter 11  time=1.34  loss=165345.25 active=105157 feature_norm=13.02\n",
      "Iter 12  time=1.34  loss=155442.38 active=102244 feature_norm=14.42\n",
      "Iter 13  time=1.30  loss=150023.42 active=99993 feature_norm=15.56\n",
      "Iter 14  time=1.32  loss=140998.12 active=99491 feature_norm=16.02\n",
      "Iter 15  time=1.29  loss=133200.03 active=97128 feature_norm=17.34\n",
      "Iter 16  time=1.27  loss=125784.62 active=96960 feature_norm=18.07\n",
      "Iter 17  time=1.27  loss=117712.48 active=95255 feature_norm=20.14\n",
      "Iter 18  time=1.27  loss=117163.23 active=93411 feature_norm=22.81\n",
      "Iter 19  time=1.28  loss=107694.13 active=94075 feature_norm=23.74\n",
      "Iter 20  time=1.26  loss=105324.79 active=93838 feature_norm=24.40\n",
      "Iter 21  time=1.27  loss=98619.73 active=91648 feature_norm=26.84\n",
      "Iter 22  time=1.27  loss=93167.18 active=90719 feature_norm=29.40\n",
      "Iter 23  time=1.27  loss=88254.59 active=89881 feature_norm=33.23\n",
      "Iter 24  time=1.25  loss=84285.97 active=90111 feature_norm=34.95\n",
      "Iter 25  time=1.27  loss=80851.89 active=89155 feature_norm=37.60\n",
      "Iter 26  time=1.27  loss=75944.87 active=87190 feature_norm=42.36\n",
      "Iter 27  time=1.26  loss=73242.14 active=86307 feature_norm=47.70\n",
      "Iter 28  time=1.25  loss=69857.40 active=86498 feature_norm=50.45\n",
      "Iter 29  time=1.28  loss=67522.79 active=85832 feature_norm=54.66\n",
      "Iter 30  time=1.25  loss=64500.48 active=84954 feature_norm=60.00\n",
      "Iter 31  time=1.26  loss=61635.72 active=83785 feature_norm=66.72\n",
      "Iter 32  time=1.27  loss=59297.18 active=83630 feature_norm=71.45\n",
      "Iter 33  time=1.24  loss=56998.30 active=82923 feature_norm=78.22\n",
      "Iter 34  time=1.26  loss=54882.59 active=82193 feature_norm=84.21\n",
      "Iter 35  time=1.25  loss=52758.63 active=81493 feature_norm=92.49\n",
      "Iter 36  time=1.26  loss=51105.52 active=81159 feature_norm=99.52\n",
      "Iter 37  time=1.25  loss=49300.50 active=80932 feature_norm=107.28\n",
      "Iter 38  time=1.25  loss=47501.51 active=79889 feature_norm=116.37\n",
      "Iter 39  time=1.25  loss=46657.89 active=77606 feature_norm=135.80\n",
      "Iter 40  time=1.28  loss=44514.95 active=78283 feature_norm=140.07\n",
      "Iter 41  time=1.27  loss=43879.64 active=78154 feature_norm=143.64\n",
      "Iter 42  time=1.26  loss=42375.89 active=76315 feature_norm=161.80\n",
      "Iter 43  time=1.28  loss=41426.01 active=76201 feature_norm=165.84\n",
      "Iter 44  time=1.27  loss=40760.45 active=76172 feature_norm=169.89\n",
      "Iter 45  time=1.27  loss=39949.56 active=75307 feature_norm=177.36\n",
      "Iter 46  time=1.26  loss=39282.23 active=74510 feature_norm=183.42\n",
      "Iter 47  time=1.27  loss=38747.83 active=74237 feature_norm=187.61\n",
      "Iter 48  time=1.27  loss=38264.97 active=72658 feature_norm=194.52\n",
      "Iter 49  time=1.26  loss=37988.71 active=71608 feature_norm=200.44\n",
      "Iter 50  time=1.27  loss=37659.48 active=71751 feature_norm=202.37\n",
      "Iter 51  time=1.27  loss=37463.56 active=70341 feature_norm=204.95\n",
      "Iter 52  time=1.26  loss=37209.09 active=68903 feature_norm=208.98\n",
      "Iter 53  time=1.27  loss=37030.88 active=68623 feature_norm=210.02\n",
      "Iter 54  time=1.26  loss=36898.33 active=68577 feature_norm=210.37\n",
      "Iter 55  time=1.26  loss=36735.14 active=68073 feature_norm=210.95\n",
      "Iter 56  time=1.26  loss=36575.35 active=67850 feature_norm=211.21\n",
      "Iter 57  time=1.27  loss=36440.09 active=67456 feature_norm=211.43\n",
      "Iter 58  time=1.28  loss=36308.11 active=67147 feature_norm=211.85\n",
      "Iter 59  time=1.27  loss=36179.10 active=66664 feature_norm=212.46\n",
      "Iter 60  time=1.25  loss=36071.11 active=66220 feature_norm=212.98\n",
      "Iter 61  time=1.27  loss=35965.56 active=65610 feature_norm=213.94\n",
      "Iter 62  time=1.26  loss=35854.21 active=65140 feature_norm=214.83\n",
      "Iter 63  time=1.25  loss=35758.10 active=64822 feature_norm=215.97\n",
      "Iter 64  time=1.27  loss=35673.31 active=64733 feature_norm=216.72\n",
      "Iter 65  time=1.27  loss=35603.77 active=64484 feature_norm=217.51\n",
      "Iter 66  time=1.26  loss=35534.97 active=64333 feature_norm=218.09\n",
      "Iter 67  time=1.26  loss=35467.88 active=64165 feature_norm=218.78\n",
      "Iter 68  time=1.27  loss=35412.09 active=63977 feature_norm=219.17\n",
      "Iter 69  time=1.28  loss=35356.53 active=63784 feature_norm=219.73\n",
      "Iter 70  time=1.27  loss=35308.70 active=63586 feature_norm=220.02\n",
      "Iter 71  time=1.27  loss=35257.39 active=63488 feature_norm=220.39\n",
      "Iter 72  time=1.28  loss=35215.97 active=63287 feature_norm=220.61\n",
      "Iter 73  time=1.27  loss=35175.40 active=63069 feature_norm=220.94\n",
      "Iter 74  time=1.32  loss=35139.59 active=62905 feature_norm=221.12\n",
      "Iter 75  time=1.30  loss=35103.50 active=62726 feature_norm=221.45\n",
      "Iter 76  time=1.30  loss=35071.73 active=62611 feature_norm=221.59\n",
      "Iter 77  time=1.29  loss=35041.66 active=62498 feature_norm=221.83\n",
      "Iter 78  time=1.30  loss=35015.75 active=62370 feature_norm=221.97\n",
      "Iter 79  time=1.27  loss=34989.77 active=62259 feature_norm=222.19\n",
      "Iter 80  time=1.27  loss=34965.45 active=62146 feature_norm=222.30\n",
      "Iter 81  time=1.28  loss=34941.18 active=62090 feature_norm=222.52\n",
      "Iter 82  time=1.26  loss=34916.68 active=61982 feature_norm=222.62\n",
      "Iter 83  time=1.27  loss=34895.29 active=61930 feature_norm=222.82\n",
      "Iter 84  time=1.27  loss=34872.16 active=61856 feature_norm=222.89\n",
      "Iter 85  time=1.25  loss=34853.66 active=61805 feature_norm=223.07\n",
      "Iter 86  time=1.27  loss=34829.75 active=61729 feature_norm=223.15\n",
      "Iter 87  time=1.26  loss=34815.59 active=61664 feature_norm=223.31\n",
      "Iter 88  time=1.26  loss=34790.78 active=61558 feature_norm=223.41\n",
      "Iter 89  time=1.28  loss=34777.36 active=61489 feature_norm=223.57\n",
      "Iter 90  time=1.27  loss=34753.99 active=61429 feature_norm=223.68\n",
      "Iter 91  time=1.26  loss=34741.72 active=61386 feature_norm=223.84\n",
      "Iter 92  time=1.27  loss=34718.19 active=61327 feature_norm=223.93\n",
      "Iter 93  time=1.26  loss=34709.01 active=61260 feature_norm=224.09\n",
      "Iter 94  time=1.25  loss=34685.77 active=61228 feature_norm=224.20\n",
      "Iter 95  time=1.25  loss=34678.50 active=61173 feature_norm=224.36\n",
      "Iter 96  time=1.26  loss=34653.96 active=61143 feature_norm=224.47\n",
      "Iter 97  time=1.25  loss=34647.64 active=61101 feature_norm=224.63\n",
      "Iter 98  time=1.26  loss=34623.14 active=61072 feature_norm=224.74\n",
      "Iter 99  time=1.27  loss=34617.93 active=61041 feature_norm=224.90\n",
      "Iter 100 time=1.28  loss=34593.64 active=61018 feature_norm=225.00\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 134.623\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 61018 (137852)\n",
      "Number of active attributes: 30392 (92810)\n",
      "Number of active labels: 17 (17)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wc72da/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=False, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100, verbose=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False, verbose = True)\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on the test set.\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model performance.\n",
    "There is much more O entities in data set, but we’re more interested in other entities. To account for this we’ll use averaged F1 score computed for all labels except for O. sklearn-crfsuite.metrics package provides some useful metrics for sequence classification task, including this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-geo',\n",
       " 'B-org',\n",
       " 'B-gpe',\n",
       " 'B-tim',\n",
       " 'B-per',\n",
       " 'I-geo',\n",
       " 'I-org',\n",
       " 'I-per',\n",
       " 'I-tim',\n",
       " 'B-eve',\n",
       " 'I-eve',\n",
       " 'I-gpe',\n",
       " 'B-nat',\n",
       " 'I-nat',\n",
       " 'B-art',\n",
       " 'I-art']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.850384474022429\n"
     ]
    }
   ],
   "source": [
    "f1_score = flat_f1_score(y_test, y_pred, average = 'weighted', labels =labels)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wc72da/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.35      0.09      0.15        85\n",
      "       B-eve       0.54      0.40      0.46        67\n",
      "       B-geo       0.86      0.91      0.88      7387\n",
      "       B-gpe       0.97      0.93      0.95      3235\n",
      "       B-nat       0.65      0.38      0.48        34\n",
      "       B-org       0.80      0.73      0.76      4033\n",
      "       B-per       0.84      0.82      0.83      3401\n",
      "       B-tim       0.94      0.88      0.91      4169\n",
      "       I-art       0.29      0.10      0.15        70\n",
      "       I-eve       0.32      0.26      0.29        46\n",
      "       I-geo       0.82      0.82      0.82      1400\n",
      "       I-gpe       0.90      0.51      0.65        51\n",
      "       I-nat       1.00      0.44      0.62         9\n",
      "       I-org       0.80      0.81      0.80      3216\n",
      "       I-per       0.85      0.89      0.87      3451\n",
      "       I-tim       0.85      0.77      0.81      1374\n",
      "           O       0.99      0.99      0.99    176643\n",
      "\n",
      "    accuracy                           0.97    208671\n",
      "   macro avg       0.75      0.63      0.67    208671\n",
      "weighted avg       0.97      0.97      0.97    208671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let’s check what classifier learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-geo  -> I-geo   8.952345\n",
      "B-per  -> I-per   8.161055\n",
      "B-art  -> I-art   8.046919\n",
      "I-art  -> I-art   7.872114\n",
      "B-tim  -> I-tim   7.772303\n",
      "I-tim  -> I-tim   7.625285\n",
      "I-eve  -> I-eve   7.497199\n",
      "B-eve  -> I-eve   7.488832\n",
      "I-geo  -> I-geo   7.314430\n",
      "B-nat  -> I-nat   7.254202\n",
      "B-gpe  -> I-gpe   7.054031\n",
      "I-org  -> I-org   6.963610\n",
      "B-org  -> I-org   6.886536\n",
      "I-per  -> I-per   6.842387\n",
      "I-gpe  -> I-gpe   5.869712\n",
      "I-nat  -> I-nat   5.553232\n",
      "O      -> B-per   4.488595\n",
      "O      -> O       4.349097\n",
      "O      -> B-tim   2.757242\n",
      "B-per  -> B-org   2.563365\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-nat  -> O       -0.321871\n",
      "I-art  -> B-tim   -0.340492\n",
      "I-art  -> B-geo   -0.345440\n",
      "I-org  -> O       -0.414760\n",
      "B-org  -> B-geo   -0.415830\n",
      "B-art  -> B-geo   -0.423549\n",
      "B-gpe  -> B-eve   -0.442220\n",
      "I-gpe  -> O       -0.487981\n",
      "B-art  -> O       -0.589518\n",
      "B-tim  -> B-art   -0.702691\n",
      "I-nat  -> O       -0.721194\n",
      "B-gpe  -> B-art   -0.792080\n",
      "B-eve  -> O       -0.830459\n",
      "B-tim  -> B-gpe   -0.944603\n",
      "I-tim  -> B-gpe   -0.952408\n",
      "I-art  -> O       -0.975745\n",
      "I-gpe  -> B-geo   -1.040417\n",
      "I-geo  -> B-gpe   -1.243094\n",
      "I-per  -> B-geo   -1.864294\n",
      "I-org  -> B-geo   -1.893246\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically transitions O -> I should be the most unlikely, but since they never occur, the `all_possible_transitions=False` flag makes sure they get ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the state features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "8.435485 O        word.lower():month\n",
      "7.990317 O        word.lower():last\n",
      "7.266817 B-gpe    word.lower():niger\n",
      "7.227985 B-org    word.lower():philippine\n",
      "6.555801 B-per    word.lower():prime\n",
      "6.485253 B-per    word.lower():vice\n",
      "6.411785 B-gpe    word.lower():nepal\n",
      "6.385589 B-org    word.lower():hamas\n",
      "6.336515 B-gpe    word.lower():afghan\n",
      "6.316728 B-geo    word.lower():mid-march\n",
      "6.250280 O        word.lower():chairman\n",
      "6.174906 B-tim    word.lower():january\n",
      "6.152378 B-org    word.lower():mid-march\n",
      "6.067365 B-org    word.lower():al-qaida\n",
      "6.052084 O        word.lower():year\n",
      "5.958665 O        word.lower():week\n",
      "5.950401 B-tim    word.lower():2000\n",
      "5.901075 B-tim    word.lower():february\n",
      "5.858865 B-tim    +1:word.lower():week\n",
      "5.853850 B-gpe    word.lower():korean\n",
      "5.768011 B-per    word.lower():obama\n",
      "5.765340 B-tim    word.lower():weekend\n",
      "5.654652 B-geo    -1:word.lower():hamas\n",
      "5.568650 B-tim    word.lower():multi-candidate\n",
      "5.554584 B-tim    word.lower():one-year\n",
      "5.425137 B-org    -1:word.lower():rice\n",
      "5.381070 B-geo    word.lower():caribbean\n",
      "5.380655 B-tim    word.lower():august\n",
      "5.365206 O        word.lower():months\n",
      "5.351726 B-gpe    word.lower():iraqi\n",
      "\n",
      "Top negative:\n",
      "-5.695372 O        word.lower():summer\n",
      "-4.498172 O        word.lower():multi-party\n",
      "-4.373960 O        word.lower():morning\n",
      "-4.367250 O        word[-2:]:0s\n",
      "-4.125258 I-org    word.lower():secretary\n",
      "-4.066316 O        +1:word.lower():last\n",
      "-4.033834 O        +1:word.lower():ms.\n",
      "-3.951465 O        word.lower():afternoon\n",
      "-3.943824 O        +1:word.lower():condoleezza\n",
      "-3.872220 O        word.lower():one-fourth\n",
      "-3.871027 O        word.lower():night\n",
      "-3.845174 O        word[-3:]:1st\n",
      "-3.634568 I-per    word[-3:]:day\n",
      "-3.620454 O        +1:word.lower():year\n",
      "-3.615820 O        word.lower():re-establishment\n",
      "-3.614208 O        word.lower():de\n",
      "-3.596801 B-geo    word[-3:]:The\n",
      "-3.580990 B-gpe    word.lower():asian\n",
      "-3.547723 O        word.lower():westerners\n",
      "-3.501980 O        word[-2:]:03\n",
      "-3.470236 O        word.lower():today\n",
      "-3.464330 O        word[-3:]:0th\n",
      "-3.461516 O        word.lower():three-year\n",
      "-3.450669 O        +1:word.lower():next\n",
      "-3.426212 O        +1:word.lower():exact\n",
      "-3.392157 O        +1:word.lower():predictions\n",
      "-3.389403 O        word.lower():palestinian\n",
      "-3.375302 O        word.lower():decade\n",
      "-3.359996 I-org    word.lower():minister\n",
      "-3.334224 B-geo    word[-3:]:day\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(list(reversed(Counter(crf.state_features_).most_common()[-30:])))"
   ]
  },
  {
   "source": [
    "# Exercise: Improve performance by adding/removing features\n",
    "\n",
    "Come up with your own features to improve performance. You can add into the existing features, or remove features.\n",
    "\n",
    "Some ideas:\n",
    "\n",
    "- Use the prefix of the current/previous/next word.\n",
    "\n",
    "- Use the shape of a word and other linguistic features (https://spacy.io/usage/linguistic-features)\n",
    "(Tip: Store the shape of all words into a dictionary so that you do not have to invoke spaCy's method every time you encounter the same word)\n",
    "\n",
    "- Look into nltk implementation of NER for more https://github.com/nltk/nltk/blob/42262c9a7cdcb6f44ac08aebd575b5d7bf85b6ea/nltk/chunk/named_entity.py"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}