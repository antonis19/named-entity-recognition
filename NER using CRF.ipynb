{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition using CRF model\n",
    "In Natural Language Processing (NLP) an Entity Recognition is one of the common problem. The entity is referred to as the part of the text that is interested in. In NLP, NER is a method of extracting the relevant information from a large corpus and classifying those entities into predefined categories such as location, organization, name and so on. \n",
    "Information about lables: \n",
    "* geo = Geographical Entity\n",
    "* org = Organization\n",
    "* per = Person\n",
    "* gpe = Geopolitical Entity\n",
    "* tim = Time indicator\n",
    "* art = Artifact\n",
    "* eve = Event\n",
    "* nat = Natural Phenomenon\n",
    "\n",
    "        1. Total Words Count = 1354149 \n",
    "        2. Target Data Column: Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the csv file\n",
    "df = pd.read_csv('./data/ner_dataset.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1          NaN             of   IN      O\n",
       "2          NaN  demonstrators  NNS      O\n",
       "3          NaN           have  VBP      O\n",
       "4          NaN        marched  VBN      O\n",
       "5          NaN        through   IN      O\n",
       "6          NaN         London  NNP  B-geo\n",
       "7          NaN             to   TO      O\n",
       "8          NaN        protest   VB      O\n",
       "9          NaN            the   DT      O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display first 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47959</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "      <td>1048575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>47959</td>\n",
       "      <td>35178</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sentence: 40302</td>\n",
       "      <td>the</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>52573</td>\n",
       "      <td>145807</td>\n",
       "      <td>887908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sentence #     Word      POS      Tag\n",
       "count             47959  1048575  1048575  1048575\n",
       "unique            47959    35178       42       17\n",
       "top     Sentence: 40302      the       NN        O\n",
       "freq                  1    52573   145807   887908"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations : \n",
    "* There are total 47959 sentences in the dataset.\n",
    "* Number unique words in the dataset are 35178.\n",
    "* Total 17 lables (Tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
       "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
       "       'I-eve', 'I-nat'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the unique Tags\n",
    "df['Tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence #    1000616\n",
       "Word                0\n",
       "POS                 0\n",
       "Tag                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking null values, if any.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of missing values in 'Sentence #' attribute. So we will use pandas fillna technique and use 'ffill' method which propagates last valid observation forward to next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1  Sentence: 1             of   IN      O\n",
       "2  Sentence: 1  demonstrators  NNS      O\n",
       "3  Sentence: 1           have  VBP      O\n",
       "4  Sentence: 1        marched  VBN      O\n",
       "5  Sentence: 1        through   IN      O\n",
       "6  Sentence: 1         London  NNP  B-geo\n",
       "7  Sentence: 1             to   TO      O\n",
       "8  Sentence: 1        protest   VB      O\n",
       "9  Sentence: 1            the   DT      O"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class te get sentence. The each sentence will be list of tuples with its tag and pos.\n",
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                       s['POS'].values.tolist(),\n",
    "                                                       s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47959"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "#sentence with its pos and tag.\n",
    "sent = getter.get_text()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all the sentences in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47959"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Preparation\n",
    "These are the default features used by the NER in nltk. We can also modify it for our customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0] # the current word\n",
    "    postag = sent[i][1] # the POS tag of the current word\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(), # the current word (lowercase)\n",
    "        'word[-3:]': word[-3:],  # 3-character suffix\n",
    "        'word[-2:]': word[-2:],  # 3-character suffix\n",
    "        'word.isupper()': word.isupper(), # is the word uppercase?\n",
    "        'word.istitle()': word.istitle(), # is the word lowercase?\n",
    "        'word.isdigit()': word.isdigit(), # it the word a number?\n",
    "        'postag': postag, # the POS tag of the word\n",
    "        'postag[:2]': postag[:2], # last 2 character of the POS tag of the word\n",
    "    }\n",
    "    if i > 0: # if not first word add features for previous word \n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else: # if first word of sentence there is no previous word\n",
    "        features['BOS'] = True # beginning of sentence\n",
    "\n",
    "    if i < len(sent)-1: # if not last word add features for next word\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True # end of sentence\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 38367/38367 [00:10<00:00, 3665.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 137917\n",
      "Seconds required: 2.543\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=2.00  loss=1349118.68 active=136910 feature_norm=1.00\n",
      "Iter 2   time=2.01  loss=1057618.64 active=135497 feature_norm=4.40\n",
      "Iter 3   time=1.02  loss=826591.69 active=129828 feature_norm=3.85\n",
      "Iter 4   time=5.21  loss=454513.09 active=131380 feature_norm=3.24\n",
      "Iter 5   time=1.14  loss=380812.16 active=133164 feature_norm=4.08\n",
      "Iter 6   time=1.13  loss=295551.90 active=131778 feature_norm=5.87\n",
      "Iter 7   time=1.12  loss=256742.59 active=124478 feature_norm=7.20\n",
      "Iter 8   time=1.13  loss=228644.67 active=118831 feature_norm=8.19\n",
      "Iter 9   time=1.04  loss=197544.63 active=110749 feature_norm=10.38\n",
      "Iter 10  time=1.08  loss=178964.14 active=107538 feature_norm=11.70\n",
      "Iter 11  time=1.16  loss=165445.00 active=105260 feature_norm=13.10\n",
      "Iter 12  time=1.25  loss=155334.92 active=101975 feature_norm=14.46\n",
      "Iter 13  time=1.25  loss=146934.94 active=99399 feature_norm=15.78\n",
      "Iter 14  time=1.26  loss=137695.79 active=98845 feature_norm=16.28\n",
      "Iter 15  time=1.23  loss=128059.49 active=96931 feature_norm=17.53\n",
      "Iter 16  time=1.25  loss=122194.34 active=94966 feature_norm=19.69\n",
      "Iter 17  time=1.18  loss=114573.04 active=94705 feature_norm=21.27\n",
      "Iter 18  time=1.03  loss=110811.76 active=95262 feature_norm=22.21\n",
      "Iter 19  time=1.09  loss=104525.43 active=93208 feature_norm=24.62\n",
      "Iter 20  time=1.13  loss=98317.84 active=91306 feature_norm=27.38\n",
      "Iter 21  time=1.04  loss=92900.66 active=91060 feature_norm=30.12\n",
      "Iter 22  time=1.04  loss=89414.90 active=90927 feature_norm=31.74\n",
      "Iter 23  time=1.04  loss=84169.40 active=88868 feature_norm=35.73\n",
      "Iter 24  time=1.05  loss=80329.08 active=87765 feature_norm=39.58\n",
      "Iter 25  time=1.03  loss=76814.77 active=87461 feature_norm=42.41\n",
      "Iter 26  time=1.03  loss=73943.03 active=86941 feature_norm=45.55\n",
      "Iter 27  time=1.02  loss=70772.26 active=84527 feature_norm=56.94\n",
      "Iter 28  time=1.02  loss=66717.57 active=85294 feature_norm=58.93\n",
      "Iter 29  time=1.02  loss=65394.38 active=85297 feature_norm=60.75\n",
      "Iter 30  time=1.00  loss=62525.58 active=83375 feature_norm=68.28\n",
      "Iter 31  time=1.02  loss=60501.06 active=83732 feature_norm=71.30\n",
      "Iter 32  time=1.02  loss=58581.06 active=83348 feature_norm=75.91\n",
      "Iter 33  time=1.03  loss=56549.90 active=82442 feature_norm=82.84\n",
      "Iter 34  time=1.03  loss=54400.42 active=82287 feature_norm=88.60\n",
      "Iter 35  time=1.02  loss=52999.66 active=82061 feature_norm=92.68\n",
      "Iter 36  time=1.03  loss=50842.38 active=80502 feature_norm=102.63\n",
      "Iter 37  time=1.02  loss=49565.28 active=80435 feature_norm=106.48\n",
      "Iter 38  time=1.02  loss=48071.64 active=80027 feature_norm=113.39\n",
      "Iter 39  time=1.07  loss=46588.30 active=78566 feature_norm=128.38\n",
      "Iter 40  time=1.03  loss=45011.03 active=78646 feature_norm=133.15\n",
      "Iter 41  time=1.01  loss=43903.68 active=77876 feature_norm=139.15\n",
      "Iter 42  time=1.03  loss=42787.85 active=75230 feature_norm=159.91\n",
      "Iter 43  time=1.02  loss=41793.87 active=76160 feature_norm=160.51\n",
      "Iter 44  time=1.07  loss=41527.22 active=76299 feature_norm=162.10\n",
      "Iter 45  time=1.02  loss=40604.42 active=75051 feature_norm=170.72\n",
      "Iter 46  time=1.02  loss=40444.80 active=73204 feature_norm=184.16\n",
      "Iter 47  time=1.03  loss=39446.14 active=73771 feature_norm=184.60\n",
      "Iter 48  time=1.01  loss=39222.66 active=73438 feature_norm=185.51\n",
      "Iter 49  time=1.03  loss=38608.02 active=72134 feature_norm=190.78\n",
      "Iter 50  time=2.03  loss=38508.59 active=72183 feature_norm=191.85\n",
      "Iter 51  time=1.02  loss=38285.04 active=72161 feature_norm=192.13\n",
      "Iter 52  time=1.02  loss=38072.13 active=71825 feature_norm=193.62\n",
      "Iter 53  time=1.02  loss=37773.77 active=71283 feature_norm=196.27\n",
      "Iter 54  time=1.01  loss=37539.74 active=70722 feature_norm=198.52\n",
      "Iter 55  time=1.01  loss=37335.27 active=69043 feature_norm=203.08\n",
      "Iter 56  time=1.03  loss=37172.86 active=68974 feature_norm=204.47\n",
      "Iter 57  time=1.02  loss=37008.18 active=68308 feature_norm=206.86\n",
      "Iter 58  time=1.02  loss=36830.48 active=67348 feature_norm=209.93\n",
      "Iter 59  time=1.02  loss=36673.62 active=67031 feature_norm=210.70\n",
      "Iter 60  time=1.09  loss=36540.07 active=66568 feature_norm=211.60\n",
      "Iter 61  time=1.04  loss=36354.63 active=65469 feature_norm=213.90\n",
      "Iter 62  time=1.03  loss=36305.29 active=65157 feature_norm=215.12\n",
      "Iter 63  time=1.02  loss=36152.09 active=65443 feature_norm=215.59\n",
      "Iter 64  time=1.01  loss=36094.89 active=65390 feature_norm=215.96\n",
      "Iter 65  time=1.01  loss=36004.06 active=65125 feature_norm=216.52\n",
      "Iter 66  time=1.03  loss=35929.11 active=64650 feature_norm=217.75\n",
      "Iter 67  time=1.04  loss=35818.82 active=64784 feature_norm=218.09\n",
      "Iter 68  time=1.03  loss=35764.33 active=64675 feature_norm=218.50\n",
      "Iter 69  time=1.01  loss=35699.23 active=64537 feature_norm=218.90\n",
      "Iter 70  time=1.04  loss=35640.59 active=64332 feature_norm=219.48\n",
      "Iter 71  time=1.02  loss=35577.32 active=64200 feature_norm=219.85\n",
      "Iter 72  time=1.02  loss=35526.90 active=64100 feature_norm=220.28\n",
      "Iter 73  time=1.02  loss=35475.37 active=63931 feature_norm=220.61\n",
      "Iter 74  time=1.01  loss=35431.79 active=63812 feature_norm=221.06\n",
      "Iter 75  time=1.01  loss=35383.25 active=63676 feature_norm=221.29\n",
      "Iter 76  time=1.02  loss=35343.61 active=63628 feature_norm=221.62\n",
      "Iter 77  time=1.02  loss=35306.60 active=63519 feature_norm=221.78\n",
      "Iter 78  time=1.02  loss=35271.47 active=63429 feature_norm=222.08\n",
      "Iter 79  time=1.02  loss=35237.90 active=63284 feature_norm=222.28\n",
      "Iter 80  time=1.01  loss=35205.15 active=63183 feature_norm=222.55\n",
      "Iter 81  time=1.03  loss=35173.98 active=63141 feature_norm=222.72\n",
      "Iter 82  time=1.03  loss=35144.85 active=63060 feature_norm=222.95\n",
      "Iter 83  time=1.03  loss=35118.38 active=62980 feature_norm=223.11\n",
      "Iter 84  time=1.05  loss=35093.61 active=62877 feature_norm=223.33\n",
      "Iter 85  time=1.04  loss=35069.51 active=62759 feature_norm=223.47\n",
      "Iter 86  time=1.05  loss=35045.57 active=62678 feature_norm=223.68\n",
      "Iter 87  time=1.07  loss=35022.74 active=62595 feature_norm=223.81\n",
      "Iter 88  time=1.18  loss=35002.65 active=62456 feature_norm=223.99\n",
      "Iter 89  time=1.29  loss=34979.80 active=62407 feature_norm=224.10\n",
      "Iter 90  time=1.05  loss=34961.04 active=62278 feature_norm=224.25\n",
      "Iter 91  time=1.02  loss=34940.32 active=62186 feature_norm=224.36\n",
      "Iter 92  time=1.05  loss=34921.76 active=62139 feature_norm=224.52\n",
      "Iter 93  time=1.02  loss=34901.98 active=62084 feature_norm=224.61\n",
      "Iter 94  time=1.02  loss=34885.90 active=62022 feature_norm=224.76\n",
      "Iter 95  time=1.04  loss=34867.22 active=61944 feature_norm=224.84\n",
      "Iter 96  time=1.02  loss=34851.99 active=61882 feature_norm=224.98\n",
      "Iter 97  time=1.02  loss=34835.63 active=61856 feature_norm=225.06\n",
      "Iter 98  time=1.02  loss=34821.29 active=61781 feature_norm=225.19\n",
      "Iter 99  time=1.04  loss=34804.70 active=61712 feature_norm=225.27\n",
      "Iter 100 time=1.03  loss=34792.27 active=61644 feature_norm=225.39\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 112.410\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 61644 (137917)\n",
      "Number of active attributes: 30764 (92955)\n",
      "Number of active labels: 17 (17)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.131\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wc72da/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=False, c1=0.1, c2=0.1,\n",
       "    keep_tempfiles=None, max_iterations=100, verbose=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False, verbose = True)\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on the test set.\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model performance.\n",
    "There is much more O entities in data set, but we’re more interested in other entities. To account for this we’ll use averaged F1 score computed for all labels except for O. sklearn-crfsuite.metrics package provides some useful metrics for sequence classification task, including this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-geo',\n",
       " 'B-gpe',\n",
       " 'B-org',\n",
       " 'I-org',\n",
       " 'B-tim',\n",
       " 'B-per',\n",
       " 'I-per',\n",
       " 'I-tim',\n",
       " 'I-geo',\n",
       " 'B-nat',\n",
       " 'I-nat',\n",
       " 'B-art',\n",
       " 'B-eve',\n",
       " 'I-eve',\n",
       " 'I-art',\n",
       " 'I-gpe']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8511850975817504\n"
     ]
    }
   ],
   "source": [
    "f1_score = flat_f1_score(y_test, y_pred, average = 'weighted', labels =labels)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wc72da/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.44      0.15      0.22        81\n",
      "       B-eve       0.52      0.38      0.44        61\n",
      "       B-geo       0.86      0.90      0.88      7521\n",
      "       B-gpe       0.97      0.94      0.95      3219\n",
      "       B-nat       0.70      0.21      0.32        34\n",
      "       B-org       0.80      0.74      0.77      3972\n",
      "       B-per       0.85      0.83      0.84      3374\n",
      "       B-tim       0.92      0.88      0.90      4033\n",
      "       I-art       0.25      0.07      0.11        55\n",
      "       I-eve       0.38      0.19      0.25        53\n",
      "       I-geo       0.82      0.80      0.81      1462\n",
      "       I-gpe       0.93      0.62      0.74        42\n",
      "       I-nat       1.00      0.08      0.15        12\n",
      "       I-org       0.81      0.80      0.80      3362\n",
      "       I-per       0.84      0.91      0.87      3483\n",
      "       I-tim       0.81      0.79      0.80      1313\n",
      "           O       0.99      0.99      0.99    177212\n",
      "\n",
      "    accuracy                           0.97    209289\n",
      "   macro avg       0.76      0.60      0.64    209289\n",
      "weighted avg       0.97      0.97      0.97    209289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let’s check what classifier learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-geo  -> I-geo   8.414277\n",
      "B-nat  -> I-nat   7.899703\n",
      "B-org  -> I-org   7.550725\n",
      "I-org  -> I-org   7.439938\n",
      "B-art  -> I-art   7.319828\n",
      "B-per  -> I-per   7.310900\n",
      "B-tim  -> I-tim   7.291974\n",
      "B-eve  -> I-eve   7.140804\n",
      "I-tim  -> I-tim   7.100317\n",
      "B-gpe  -> I-gpe   7.048318\n",
      "I-art  -> I-art   6.849460\n",
      "I-geo  -> I-geo   6.663883\n",
      "I-eve  -> I-eve   6.617047\n",
      "I-gpe  -> I-gpe   6.331629\n",
      "I-per  -> I-per   6.033221\n",
      "O      -> B-per   4.762875\n",
      "O      -> O       4.520906\n",
      "I-nat  -> I-nat   4.269670\n",
      "O      -> B-tim   3.225079\n",
      "B-geo  -> B-tim   2.718923\n",
      "\n",
      "Top unlikely transitions:\n",
      "I-tim  -> B-org   -0.420681\n",
      "B-art  -> O       -0.441651\n",
      "B-art  -> B-per   -0.477492\n",
      "I-art  -> B-per   -0.558382\n",
      "B-tim  -> B-art   -0.574160\n",
      "I-gpe  -> O       -0.612843\n",
      "I-art  -> O       -0.623511\n",
      "I-gpe  -> B-geo   -0.629051\n",
      "B-eve  -> B-tim   -0.770985\n",
      "I-art  -> B-tim   -0.787978\n",
      "B-eve  -> O       -0.832436\n",
      "B-art  -> B-geo   -1.045687\n",
      "B-tim  -> B-gpe   -1.048469\n",
      "I-geo  -> B-gpe   -1.078524\n",
      "I-art  -> B-geo   -1.120318\n",
      "I-tim  -> B-gpe   -1.257102\n",
      "I-org  -> B-geo   -1.435209\n",
      "I-nat  -> O       -1.548182\n",
      "I-per  -> B-gpe   -1.859264\n",
      "I-per  -> B-geo   -2.127349\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically transitions O -> I should be the most unlikely, but since they never occur, the `all_possible_transitions=False` flag makes sures they get ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the state features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "8.158353 O        word.lower():last\n",
      "8.095732 O        word.lower():month\n",
      "6.864339 B-org    word.lower():philippine\n",
      "6.591011 B-tim    word.lower():multi-candidate\n",
      "6.545099 B-gpe    word.lower():niger\n",
      "6.470383 B-gpe    word.lower():afghan\n",
      "6.203209 B-per    word.lower():president\n",
      "6.152053 B-geo    word.lower():caribbean\n",
      "6.018412 B-org    -1:word.lower():rice\n",
      "6.012577 B-tim    word.lower():2000\n",
      "6.006212 B-geo    -1:word.lower():hamas\n",
      "5.850307 B-tim    word.lower():one-year\n",
      "5.814563 B-geo    word.lower():europe\n",
      "5.795934 B-per    word.lower():prime\n",
      "5.795603 B-gpe    word.lower():nepal\n",
      "5.736389 B-org    word.lower():mid-march\n",
      "5.683419 B-tim    word.lower():february\n",
      "5.647005 B-tim    word.lower():january\n",
      "5.597681 B-org    word.lower():hamas\n",
      "5.499085 B-per    word.lower():obama\n",
      "5.390410 B-per    word.lower():greenspan\n",
      "5.380266 B-tim    word.lower():august\n",
      "5.352231 B-per    word.lower():senator\n",
      "5.328137 O        word.lower():internet\n",
      "5.289210 O        word.lower():week\n",
      "5.247250 B-tim    word[-3:]:Day\n",
      "5.211255 O        word.lower():columbia\n",
      "5.142603 B-gpe    word.lower():iraqi\n",
      "5.131866 B-gpe    word[-3:]:pal\n",
      "5.126687 O        word.lower():year\n",
      "\n",
      "Top negative:\n",
      "-3.357802 O        word.lower():today\n",
      "-3.358058 B-per    word.lower():venezuela\n",
      "-3.392722 O        word.istitle()\n",
      "-3.402032 B-geo    word.isdigit()\n",
      "-3.406777 O        word.lower():evening\n",
      "-3.417569 B-geo    word[-3:]:day\n",
      "-3.437448 B-gpe    word.lower():asian\n",
      "-3.443911 O        +1:word.lower():ms.\n",
      "-3.458067 O        word[-2:]:03\n",
      "-3.489606 O        +1:word.lower():years\n",
      "-3.583558 O        +1:word.lower():months\n",
      "-3.598936 B-tim    +1:word.lower():into\n",
      "-3.604803 O        +1:word.lower():year\n",
      "-3.681661 O        word.lower():multi-party\n",
      "-3.690884 I-org    word[-2:]:lf\n",
      "-3.693445 O        word.lower():decade\n",
      "-3.701768 I-per    word[-3:]:day\n",
      "-3.723486 O        +1:word.lower():last\n",
      "-3.725593 O        +1:word.lower():mrs.\n",
      "-3.806555 O        word.lower():afternoon\n",
      "-3.830263 O        +1:word.lower():predictions\n",
      "-3.866651 O        +1:word.lower():next\n",
      "-3.884284 O        word.lower():palestinian\n",
      "-3.920837 O        word.lower():de\n",
      "-3.937544 B-gpe    word.lower():european\n",
      "-3.966673 I-org    word.lower():secretary\n",
      "-4.547055 O        word.lower():summer\n",
      "-4.603259 O        word.lower():morning\n",
      "-4.652606 B-geo    word[-3:]:The\n",
      "-5.027037 O        word[-2:]:0s\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Improve performance by adding/removing features\n",
    "\n",
    "Come up with your own features to improve performance. You can add into the existing features, or remove features.\n",
    "\n",
    "Some ideas:\n",
    "\n",
    "- Use the shape of a word and other linguistic features (https://spacy.io/usage/linguistic-features)\n",
    "\n",
    "(Tip: Store the shape of all words into a dictionary so that you do not have to invoke spaCy's method every time you encounter the same word)\n",
    "- Look into nltk implementation of NER https://github.com/nltk/nltk/blob/42262c9a7cdcb6f44ac08aebd575b5d7bf85b6ea/nltk/chunk/named_entity.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
